<section xml:id="big-o_identifying"
         xmlns:xi="http://www.w3.org/2001/XInclude">

  <title>Identifying Big-O</title>


  <p>
    Given an algorithm, how do we identify its Big-O category? We have to come up with a function
    that estimates the amount of work the algorithm does as a function of the size of its input.
    However, because we are only interested in the dominant term of that function and don't care about
    constant factors, this is easier than it might sound.
  </p>


  <subsection>
    <title>Lines of Code</title>
    <p>One tempting way to estimate the work an algorithm does is to count the number of lines of code it contains. However, this method is not very reliable because the number of lines of code does not necessarily correlate with the amount of work done.</p>
    <p>Consider <pf>double d = x * x + y * y;</pf>. Surely that involves more work than <pf>int a = 5;</pf>. The first line of code involves multiple operations: it does two multiplies, an addition, and then stores the result. That is clearly more work than the second line.</p>
    <p>And if we did some research on the processor being used, we might find that multiplication takes more machine cycles to execute than addition. So maybe each multiplication should count as 3 units of work as it takes that many machine cycles to perform. The addition might count as 1 unit of work and the assignment another unit. So the first line of code would be 3 + 3 + 1 + 1 = 8 units of work, while the second line would be just 1 unit of work.</p>
    <p>However, none of those details matter. Both lines of code take a constant amount of work. In Big-O notation, constant factors are ignored. We don't care if that is 1 unit of work or 100 units of work.
    </p>
    <insight>
      <p>The work on any line of code that does not involve a loop or function call is constant, or <m>O(1)</m>.</p>
      <p>Assignment, doing math, comparing values, accessing an element in an array, and similar operations all take constant time. Any combination of these operations takes constant time.</p>
    </insight>
    
    <p>A similar thing applies to a sequence of lines of code. Consider these two fragments:</p>
    <sidebyside widths="45% 45%">
      <program>
        int x = 5;
      </program>
      <program>
        int y = 10;
        int z = 15;
        int a = 20;
        int x = y + z - a;
      </program>
    </sidebyside>
    <p>The left fragment takes <m>O(1)</m> time.</p>
    <p>The  right fragment takes <m>O(1) + O(1) + O(1) + O(1)</m> time. <m>O(1) + O(1) + O(1) + O(1)</m> can be written as <m>4 \cdot O(1)</m>, which simplifies to <m>O(1)</m> when we drop the constant factor.</p>
    <p>In Big O terms, both fragments take <m>O(1)</m> time. The exact amount of time will clearly be different between the two fragments, but both will involve some constant amount of work and that is all that is important.</p>
    <insight>
      <p>The work in a sequence of lines of code that do not involve a loop or function call is constant, or <m>O(1)</m>.</p>
    </insight>
  </subsection>

  <subsection>
    <title>Loops</title>
    <p>Loops are where things get more interesting. The amount of work done in a loop depends on how many times the loop runs and how much work is done in each iteration.</p>
    <p>Consider this loop:</p>
    <program>
      for (int i = 0; i &lt; n; i++) {
        sum = sum + i;
      }
    </program>
    <p>The loop runs <m>n</m> times. Each time through the loop, it does a constant amount of work: adding <pf>i</pf> to <pf>sum</pf> and updating <pf>i</pf>. So the total amount of work done by the loop is <m>n \cdot O(1)</m>. Here, <m>n</m> is not a constant. If n is 100, the loop repeats 100 times. If n is 1000 it will repeat 1000 times. So we can't simply drop n like we would a constant factor. Instead, we must keep it in our Big-O expression.</p>
    <p><m>n \cdot O(1) = O(n)</m> Both sides of that equality represent <q>n times some constant</q>. So we would say that entire loop is <m>O(n)</m>.</p>
    <p>How about the loop:</p>
    <program>
      for (int i = 0; i &lt; n; i++) {
        sum = sum + i;
        if( i > max ) {
          max = i;
        }
      }
    </program>
    <p>The entire group of lines inside the loop is still <m>O(1)</m>. There is a constant amount of work inside the loop. When <m>n</m> changes, it will change the number of times the loop repeats, but it will not change the amount of work done in each iteration of the loop!</p>
    <p>So the entire loop is still <m>n \cdot O(1) = O(n)</m>.</p>

    <p>Now consider a nested loop:</p>
    <program>
      for (int i = 0; i &lt; n; i++) {
        for (int j = 0; j &lt; n; j++) {
          sum = sum + i + j;
        }
      }
    </program>
    <p>The inner loop runs <m>n</m> times. Each time through the inner loop, it does a constant amount of work. So the inner loop is <m>n \cdot O(1) = O(n)</m>.</p>
    <p>However, the outer loop also runs <m>n</m> times. Each time through the outer loop, it runs the entire inner loop, which we have determined is <m>O(n)</m>. So the entire nested loop is <m>n \cdot O(n) = O(n^2)</m>.</p>
    <insight>
      <p>When analyzing loops, multiply the number of iterations by the amount of work done in each iteration.</p>
    </insight>

    <p>What would the work be for these loops?</p>
    <program>
      for (int i = 0; i &lt; n; i++) {
        for (int j = 0; j &lt; 10; j++) {
          sum = sum + i + j;
        }
      }
    </program>

    <p>Start with the inner loop. The inner loop runs 10 times. Each time through the inner loop, it does a constant amount of work. So the inner loop is <m>10 \cdot O(1) = O(1)</m>.</p>

  </subsection>

  <subsection>
    <title>Loop Counters</title>

    <p>Loops are one of the primary ways we get non-constant work in our algorithms. But not every loop represents <m>O(n)</m> work. The amount of work depends on how many times the loop runs.</p>

    <p>Consider this loop:</p>
    <program>
      for (int i = 0; i &lt; 10; i++) {
        sum = sum + i;
      }
    </program>
    
    <p>This loop runs 10 times. Each time through the loop, it does a constant amount of work. So the total amount of work done by the loop is <m>10 \cdot O(1)</m>. Here, 10 is a constant, so we can drop it. Thus, this entire loop is <m>O(1)</m>.</p>

    <p>Because the loop ran a constant amount of times, it still represents constant work!</p>

    <p>Now consider this loop:</p>
    <program>
      for (int i = 0; i &lt; n / 2; i++) {
        sum = sum + i;
      }
    </program>

    <p>How many times does it repeat? <m>n / 2</m> times. Which means the total amount of work done by the loop is <m>(n / 2) \cdot O(1)</m>. Dividing by 2 is a constant factor (we could instead multiply by 0.5), so we can drop it. Thus, this entire loop is <m>O(n)</m>.</p>

    <p>Even though the loop runs only half as many times as a loop that runs <m>n</m> times, it is still <m>O(n)</m> because the amount of work increases in a linear fashion with the size of n. If n doubles, this loop will repeat twice as many times.</p>

    <p>By the same logic, a loop that counted from 0 to <pf>3*n</pf> would also be <m>O(n)</m>. Repeating 3 times as many iterations is still a constant factor, so it does not change the Big O classification.</p>

    <insight>
      <p>If a loop counts up to some constant multiple of <m>n</m>, the number of iterations is still proportional to <m>n</m>, so the loop is <m>O(n)</m>.</p>
    </insight>

    <p>Next, let us consider this loop:</p>

    <program>
      for (int i = 0; i &lt;= n; i += 2) {
        sum = sum + i;
      }
    </program>

    <p>What values does <pf>i</pf> count through?</p>

    <console><output>0, 2, 4, 6, ..., n</output></console>

    <p>The sequence <c>0, 1, 2, ..., n</c> is <m>n + 1</m> items long or <m>O(n)</m> (plus some constant doesn't matter since n is dominant). The sequence above is roughly half as long since it skips every other number. It is approximately <m>n / 2</m> items long. But <m>n / 2</m> is a constant factor of <m>n</m>, so the loop is still <m>O(n)</m>!</p>

    <p>If we counted by 10's like <c>0, 10, 20, ... </c>, the length of the sequence would be approximately <m>n / 10</m>. But 1/10 is a constant factor, so the loop is still <m>O(n)</m>.</p>

    <insight>
      <p>If the loop counter changes by a constant amount each time (like 2 in this example), the number of iterations is still proportional to <m>n</m>, so the loop is <m>O(n)</m>.</p>
    </insight>

    <p>Now let us consider this loop:</p>
    <program>
      for (int i = 1; i &lt;= n; i *= 2) {
        sum = sum + i;
      }
    </program>

    <p>Note that this time the counter is doubled at each iteration. Here, the values we count through are:</p>
    <console><output>1, 2, 4, 8, ..., n</output></console>
    <p>Each time through the loop, we multiply <pf>i</pf> by 2. So how many times can we double 1 before we exceed n? We need to solve the equation <m>2^k = n</m> to find out. Taking the logarithm base 2 of both sides gives us <m>k = \log_2(n)</m>. So this loop runs about <m>\log_2(n)</m> times. Each time through the loop, it does a constant amount of work. So the total amount of work done by the loop is <m>\log_2(n) \cdot O(1) = O(\log n)</m>.</p>

    <p>Another variation on this pattern would be the loop:</p>
    <program>
      for (int i = n; i &gt; 0; i /= 2) {
        sum = sum + i;
      }
      </program>
    
    <p>Here, we start at n and divide by 2 each time. How many times can we divide n by 2 before we get down to 1? But this just counts through the same values of i in reverse. (<c>n, n/2, n/4, ..., 1</c>) So this loop is also <m>O(\log n)</m>.</p>

    <insight>
      <p>If the loop control variable is multiplied or divided by a constant factor each time, the number of iterations is proportional to <m>\log n</m>, so the loop is <m>O(\log n)</m>.</p>
    </insight>

  </subsection>
  
  <subsection>
    <title>Putting it Together</title>
    
    <p>Now let us consider a longer chunk of code:</p>

    <program>
      int sum = 0;
      for (int i = 0; i &lt; n; i++) {
        for (int j = 0; j &lt; n; j *= 2) {
          sum = sum + i + j;
        }
      }
      for (int k = 1; k &lt;= n/2; k++) {
        int x = 1 + k;
        sum = sum + x;
      }
      return sum;
    </program>

    <p>To analyze this code, we can:
      <li>
        <p>Call any sequence of lines that do not involve loops or function calls <m>O(1)</m>.</p>
        <p>Calculate the number of iterations of each loop.</p>
        <p>When loops are nested, multiply the number of iterations of each loop to get the total number of iterations.</p>
        <p>Add whatever remains and only keep the dominant term.</p>
      </li>
    </p>

    <investigation label="big-o_identifying-ex-1">
      <introduction><p>We will analyze the given code to determine its Big-O complexity.</p></introduction>
      <task>
        <title>Start</title>  
        <p>First, we replace non-loops with <m>O(1)</m>.</p>
        
    <program>
      int sum = 0;
      for (int i = 0; i &lt; n; i++) {
        for (int j = 0; j &lt; n; j *= 2) {
          sum = sum + i + j;
        }
      }
      for (int k = 1; k &lt;= n/2; k++) {
        int x = 1 + k;
        sum = sum + x;
      }
      return sum;
    </program>
      </task>
      <task>
        <title>Identify loop lengths</title>  
        <p>That results in the following.</p>
        
    <program>
      // O(1)
      for (int i = 0; i &lt; n; i++) {
        for (int j = 0; j &lt; n; j *= 2) {
          // O(1)
        }
      }
      for (int k = 1; k &lt;= n/2; k++) {
        // O(1)
      }
      // O(1)
    </program>
        <p>Next, we identify the lengths of each loop.</p>
      </task>
      <task>
        <title>Identify loop lengths</title>  
        <p>Here, each loop is labeled with the number of repetitions. Note that:
          <ul>
            <li> the <pf>i</pf> loop counts from 0 to n by 1s, so it has a length of <m>O(n)</m></li>
            <li> the <pf>j</pf> loop, which multiplies by 2 at each step, has a length of <m>O(\log n)</m></li>
            <li> the <pf>k</pf> loop, which counts from 1 up to <m>n/2</m> by 1s, has a length of <m>O(n)</m></li>
          </ul>
        </p>
        
    <program>
      // O(1)
      loop O(n) times {  (i loop)
        loop O(log n) times {  (j loop)
          // O(1)
        }
      }
      loop O(n) times { (k loop)
        // O(1)
      }
      // O(1)
    </program>
        <p>Next, we multiply loops by what is inside them.</p>
      </task>

      <task>
        <title>Multiply Loops by Contents</title>  
        <p>We start with the inner loop (<pf>j</pf> loop). It runs <m>O(\log n)</m> times, and its contents are <m>O(1)</m>, so the total is <m>O(\log n) \cdot O(1) = O(\log n)</m>.</p>
    <program>
      // O(1)
      loop O(n) times { (i loop)
        // O(log n)  (j loop)
      }
      loop O(n) times { (k loop)
        // O(1)
      }
      // O(1)
    </program>
        <p>Now we have no nested loops, so we can multiply the remaining loops by their contents.</p>
      </task>

      <task>
        <title>Multiply Loops by Contents</title>  
        <p>The <pf>i</pf> loop runs <m>O(n)</m> times, and its contents are <m>O(\log n)</m>, so the total is <m>O(n) \cdot O(\log n) = O(n \log n)</m>.</p>
    <program>
      // O(1)
      // O(n log n) (i loop with j inside)

      loop O(n) times { (k loop)
        // O(1)
      }
      // O(1)
    </program>
        <p>Next the <pf>k</pf> loop.</p>
      </task>

      <task>
        <title>Multiply Loops by Contents</title>  
        <p>The <pf>k</pf> loop runs <m>O(n)</m> times, and its contents are <m>O(1)</m>, so the total is <m>O(n) \cdot O(1) = O(n)</m>.</p>
    <program>
      // O(1)
      // O(n log n) (i loop with j inside)
      // O(n) (k loop)
      // O(1)
    </program>
        <p>We have <m>O(1) + O(n \log n) + O(n) + O(1)</m>. That is <m>O(n \log n) + O(n) + 2 \cdot O(1)</m> which is just <m>O(n \log n) + O(n) + 2 \cdot O(1)</m>. Of those, the dominant term is <m>O(n \log n)</m>. So the Big-O complexity is <m>O(n \log n)</m>.</p>
        <p>Since all we care about is the dominant term, we don't even have to add up the various terms. We can simply look at the four terms we ended up with and pick the largest one.</p>
      </task>
    </investigation>
  </subsection>

  <!-- TODO: Parsons BigO analysis-->


</section>